{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2aa4500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f7f38",
   "metadata": {},
   "source": [
    "# Jacobi and Gauss-Seidel \n",
    "We again consider the Poisson problem where we have the system of equations. We can write this equation as\n",
    "\\begin{align*}\n",
    "    u_{ij} = \\frac{1}{4}(u_{i-1,j} + u_{i+1,j} + u_{i, j-1} + u_{i, j+1}) - \\frac{h^2}{4}f_{ij}\n",
    "\\end{align*}\n",
    "\n",
    "This equation suggests the following iterative method to produce a new estimate $u^{[k+1]}$ from a current guess $u^{[k]}$:\n",
    "\n",
    "\\begin{align*}\n",
    "    u_{ij}^{[k+1]} = \\frac{1}{4}\\left( u_{i-1,j}^{[k]} + u_{i+1,j}^{[k]} + u_{i,j-1}^{[k]} + u_{i,j+1}^{[k]}\\right) \n",
    "                     - \\frac{h^2}{4}f_{ij}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "30ffe57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_1 = 10\n",
    "h_1 = 1/(m_1+1)\n",
    "\n",
    "def u_sol_1(x, y):\n",
    "    return(np.sin(x) + np.sin(y))\n",
    "\n",
    "def f_1(x, y):\n",
    "    return(-np.sin(x) - np.sin(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8cee6c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Poisson_GJ(u_sol, f, m, h, *arg):\n",
    "    if arg == ():\n",
    "         arg = math.floor(m**2*math.log(m))\n",
    "    else:\n",
    "        arg = arg[0]\n",
    "            \n",
    "    u_approx = np.ones((m + 2, m + 2))\n",
    "\n",
    "    # Initializing the boundary terms with the boundary condition\n",
    "    for i in range(m + 2):\n",
    "        u_approx[0][i] = u_sol(0, i*h)\n",
    "        u_approx[m+1][i] = u_sol(1, i*h)\n",
    "        if i != 0 and i != m + 1:\n",
    "            u_approx[i][0] = u_sol(0, i*h)\n",
    "            u_approx[i][-1] = u_sol(1, i*h)\n",
    "\n",
    "\n",
    "    u_new = np.copy(u_approx)\n",
    "\n",
    "    for k in range(arg):\n",
    "        for i in range(1, m + 1):\n",
    "            for j in range(1, m + 1):\n",
    "                u_new[i, j]=0.25*(u_approx[i-1][j]+u_approx[i+1][j]+u_approx[i][j-1]+u_approx[i][j+1] - \n",
    "                                  h*h*f(i*h,j*h))\n",
    "\n",
    "        u_approx = np.copy(u_new)\n",
    "        \n",
    "    return(u_approx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bc0ac1",
   "metadata": {},
   "source": [
    "Instead of using a new matrix to store the updates value, we can store them in the same matrix and use those new updated values, therefore the new equation is\n",
    "\\begin{align*}\n",
    "    u_{ij}^{[k+1]} = \\frac{1}{4}\\left(u_{i-1,j}^{[k + 1]} + u_{i+1,j}^{[k]} + u_{i,j-1}^{[k + 1]} + u_{i,j+1}^{[k]}                       \\right) - \\frac{h^2}{4}f_{ij}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bc0ebf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the boundary terms with the boundary condition\n",
    "    \n",
    "def Poisson_GS(u_sol, f, m, h, *arg):\n",
    "    \n",
    "    if arg == ():\n",
    "        arg = math.floor(m**2*math.log(m))\n",
    "    else:\n",
    "        arg = arg[0]\n",
    "        \n",
    "        \n",
    "    u_approx = np.ones((m + 2, m + 2))\n",
    "    \n",
    "    for i in range(m + 2):\n",
    "        u_approx[0][i] = u_sol(0, i*h)\n",
    "        u_approx[m+1][i] = u_sol(1, i*h)\n",
    "        if i != 0 and i != m + 1:\n",
    "            u_approx[i][0] = u_sol(0, i*h)\n",
    "            u_approx[i][-1] = u_sol(1, i*h)\n",
    "\n",
    "\n",
    "    for k in range(arg):\n",
    "        for i in range(1, m + 1):\n",
    "            for j in range(1, m + 1):\n",
    "                u_approx[i, j]=0.25*(u_approx[i-1][j]+u_approx[i+1][j]+u_approx[i][j-1]+u_approx[i][j+1] - \n",
    "                                     h*h*f(i*h,j*h))\n",
    "\n",
    "    return(u_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "890fa732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "def Seidel(A, f, *arg):\n",
    "    m = len(f)\n",
    "    if arg == ():\n",
    "        arg = math.floor(m**2*math.log(m))\n",
    "    else:\n",
    "        arg = arg[0]\n",
    "    unknowns = np.zeros(m)\n",
    "    \n",
    "    for i in range(arg):\n",
    "        for i in range(m):\n",
    "            unknowns[i] = f[i]/A[i,i]\n",
    "            for j in range(m):\n",
    "                if j != i:\n",
    "                    unknowns[i] -= (A[i,j]/A[i,i])*unknowns[j]\n",
    "                    \n",
    "    return(unknowns)\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "817b3be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jacobi(A, f, *arg):\n",
    "    m = len(f)\n",
    "    if arg == ():\n",
    "        arg = math.floor(m**2*math.log(m))\n",
    "    else:\n",
    "        arg = arg[0]\n",
    "    unknowns = np.zeros(m)\n",
    "    unknowns_1 = np.zeros(m)\n",
    "    \n",
    "    for i in range(arg):\n",
    "        for i in range(m):\n",
    "            unknowns_1[i] = f[i]/A[i,i]\n",
    "            for j in range(m):\n",
    "                if j != i:\n",
    "                    unknowns_1[i] -= (A[i,j]/A[i,i])*unknowns[j]\n",
    "                    \n",
    "            unknows = np.copy(unknowns_1)\n",
    "                    \n",
    "    return(unknowns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5b01129c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error using Gauss Jacobi method 0.22543008659234853\n",
      "Error using Gauss Seidel method 0.0780381195287998\n"
     ]
    }
   ],
   "source": [
    "x = np.linspace(0, 1, m_1 + 2)\n",
    "y = np.linspace(0, 1, m_1 + 2)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "sol = u_sol_1(X, Y)\n",
    "\n",
    "approx_GJ = Poisson_GJ(u_sol_1, f_1, m_1, h_1, 10)\n",
    "approx_GS = Poisson_GS(u_sol_1, f_1, m_1, h_1, 10)\n",
    "    \n",
    "print('Error using Gauss Jacobi method',np.max(abs(approx_GJ - sol)))\n",
    "    \n",
    "print('Error using Gauss Seidel method',np.max(abs(approx_GS - sol)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80811fab",
   "metadata": {},
   "source": [
    "# Successive overrelaxation\n",
    "The Gauss-Seidel update moves $u_i$ in the right direction but is far too conservative in the amount allows $u_i$ to move. This suggest that we use the following two-stage update, illustrated again for the problem $u'' = f$:\n",
    "\\begin{align*}\n",
    "    u_i^{\\text{GS}} &= \\frac{1}{2}\\left( u_{i-1}^{[k+1]} + u_{i+1}^{[k]}  - h^2f_i \\right), \\\\\n",
    "    u_i^{[k+1]} &= u_i^{[k]} + \\omega \\left( u_i^{\\text{GS}} - u_i^{[k]} \\right)\n",
    "\\end{align*}\n",
    "\n",
    "The formulas above can be combined to yield \n",
    "\\begin{align*}\n",
    "    u_i^{[k+1]} = \\frac{\\omega}{2} \\left( u_{i-1}^{[k+1]} + u_{i+1}^{[k]} - h^2f_i \\right) + (1-\\omega)u_i^{[k]}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "afc68f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sor_method(f, m, h, alpha, beta, *arg):\n",
    "    if arg == ():\n",
    "        arg = math.floor(m**2*math.log(m))\n",
    "    else:\n",
    "        arg = arg[0]\n",
    "        \n",
    "    u_approx = np.ones(m+2)\n",
    "    u_approx[0] = alpha\n",
    "    u_approx[m + 1] = beta\n",
    "    \n",
    "    omega = 2 - 2*np.pi*h\n",
    "    \n",
    "    for k in range(arg):\n",
    "        for i in range(1, m + 1):\n",
    "            u_approx[i] = (omega/2)*(u_approx[i-1] + u_approx[i+1] - h*h*f(i*h)) + (1-omega)*u_approx[i]\n",
    "            \n",
    "    return(u_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "27a96b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_2(x):\n",
    "    return(-np.sin(x))\n",
    "alpha = np.sin(0)\n",
    "beta = np.sin(1)\n",
    "\n",
    "    \n",
    "num_sol = sor_method(f_2, m_1, h_1, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f7a10c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.121713898164181e-05\n"
     ]
    }
   ],
   "source": [
    "x = np.linspace(0, 1, m_1 + 2)\n",
    "sol = np.sin(x)\n",
    "print(np.max(abs(sol - num_sol)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593d1470",
   "metadata": {},
   "source": [
    "# The method of steepest descent\n",
    "This is a method to solve the general linear system $Au = f$.Here the method is first motivated as a descent method for solving a minimization problem. Consider the function $ \\phi : \\mathbb{R}^m \\rightarrow \\mathbb{R} $ defined by\n",
    "\\begin{align*}\n",
    "    \\phi(u) = \\frac{1}{2}u^TAu-u^Tf.\n",
    "\\end{align*}\n",
    "Let $u^*$ be the point where minimum occurs, this implies $ \\nabla\\phi(u^*) = 0$ and \n",
    "\\begin{align*}\n",
    "    \\nabla\\phi(u) = Au - f\n",
    "\\end{align*}\n",
    "\n",
    "This implies that $u^*$ is the solution to the linear system $Au = f$.\n",
    "\n",
    "From one estimate $u_{k-1}$ to $u^*$ we wish to obtain a better estimate $u_k$ by moving downhill, based on values of $\\phi(u)$. Since the gradient vector $\\nabla\\phi(u)$ always points in the direction of most rapid increase of $\\phi$. So we want to set\n",
    "\\begin{align*}\n",
    "    u_k = u_{k-1} - \\alpha_{k-1}\\nabla\\phi(u_{k-1})\n",
    "\\end{align*}\n",
    "for some scalar $alpha_{k-1}$, chosen to solve the minimizaion problem\n",
    "\\begin{align*}\n",
    "    \\min_{\\alpha \\in \\mathbb{R}} \\phi(u_{k-1} - \\alpha\\nabla(u_{k-1}))\n",
    "\\end{align*}\n",
    "Let $r_k = f - Au_k$ is called the residual vector based on the current approximation $u_k$. Solving the minimization problem for $\\alpha$ we get\n",
    "\\begin{align*}\n",
    "    \\alpha = \\frac{r^Tr}{r^TAr}\n",
    "\\end{align*}\n",
    "\n",
    "This gives us the below algorithm \\\\\n",
    "\n",
    "&nbsp; &nbsp; &nbsp; &nbsp; choose a guess $u_0$   \n",
    "&nbsp; &nbsp; &nbsp; &nbsp; $r_0 = f-Au_0$         \n",
    "&nbsp; &nbsp; &nbsp; &nbsp; for $ k = 1, 2, \\ldots $  \n",
    "&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $w_{k-1} = Ar_{k-1}$  \n",
    "\n",
    "&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $\\alpha_{k-1} = (r^T_{k-1}r_{k-1})/(r^T_{k-1}w_{k-1})$ \n",
    "\n",
    "&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $u_k = u_{k-1} + \\alpha_{k-1}r_{k-1}$ \n",
    "\n",
    "&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; $r_k = r_{k-1} - \\alpha_{k-1}w_{k-1}$   \n",
    "\n",
    "&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if $\\|{r_k}\\|$ is less than some tolerance then stop\n",
    "\n",
    "&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2de944ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def steep_des(A, f):\n",
    "    # Initial guess\n",
    "    u_approx = np.ones(len(f))\n",
    "    residual = f - np.dot(A, u_approx)\n",
    "    while max(abs(residual)) >= pow(10, -3):\n",
    "        w = np.dot(A, residual)\n",
    "        print(w, residual)\n",
    "        alpha = np.dot(residual, residual)/np.dot(residual, w)\n",
    "        u_approx = u_approx + alpha*residual\n",
    "        residual = residual - alpha*w\n",
    "        \n",
    "    \n",
    "    return(u_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8b86dfb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5. -7.] [-1. -3.]\n",
      "[1.53846154 0.30769231] [ 0.92307692 -0.30769231]\n",
      "[-0.87912088 -1.23076923] [-0.17582418 -0.52747253]\n",
      "[0.27049873 0.05409975] [ 0.16229924 -0.05409975]\n",
      "[-0.1545707  -0.21639899] [-0.03091414 -0.09274242]\n",
      "[0.04756022 0.00951204] [ 0.02853613 -0.00951204]\n",
      "[-0.02717727 -0.03804817] [-0.00543545 -0.01630636]\n",
      "[0.00836224 0.00167245] [ 0.00501734 -0.00167245]\n",
      "[-0.00477842 -0.00668979] [-0.00095568 -0.00286705]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.3326472 , -0.66617657])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steep_des([[2, 1], [1, 2]], [2, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d080128f",
   "metadata": {},
   "source": [
    "# The conjugate-gradient algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "06b96dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjugate_grad(A, f):\n",
    "    # Initial guess\n",
    "    u_approx = np.zeros(len(f))\n",
    "    residual = f - np.dot(A, u_approx)\n",
    "    p_search = np.copy(residual)\n",
    "    for i in range(len(f)):\n",
    "        w = np.dot(A, p_search)\n",
    "        alpha = np.dot(residual, residual)/np.dot(p_search, w)\n",
    "        u_approx = u_approx + alpha * p_search\n",
    "        residual_new = residual - alpha * w\n",
    "        if np.max(abs(residual_new)) != 0:\n",
    "            beta = np.dot(residual_new, residual_new)/np.dot(residual, residual)\n",
    "            p_search = residual_new + beta * p_search\n",
    "            residual = np.copy(residual_new)\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "        \n",
    "        \n",
    "    return(u_approx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "991ad082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.33333333, -0.66666667])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conjugate_grad([[2, 1], [1, 2]], [2, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868fcd46",
   "metadata": {},
   "source": [
    "# GMRES algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "d628f4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmres(A, f):\n",
    "    u_0 = np.zeros(len(f))\n",
    "    r_0 = f - np.dot(A, u_0)\n",
    "    \n",
    "    Q = [r_0/np.linalg.norm(r_0)]\n",
    "    Hess = np.zeros((len(f) + 1, len(f)))\n",
    "    \n",
    "    for k in range(len(f)):\n",
    "        v = np.dot(A, Q[k])\n",
    "        for i in range(k + 1):\n",
    "            Hess[i, k] = np.dot(Q[i], v)\n",
    "            v -= Hess[i, k]*Q[i]\n",
    "           \n",
    "        \n",
    "        Hess[k + 1, k] = np.linalg.norm(v)\n",
    "        if k != len(f) - 1:\n",
    "            Q.append(v/Hess[k + 1, k])\n",
    "            \n",
    "        eta = np.zeros(k + 1)\n",
    "        eta[0] = np.linalg.norm(r_0)\n",
    "            \n",
    "        y_k = np.linalg.lstsq(Hess[:k + 1, :k], eta)[0]\n",
    "        \n",
    "        \n",
    "#         print(y_k, Q[:][:k+1], len(Q[0]))\n",
    "\n",
    "        \n",
    "        if np.linalg.norm(eta - np.dot(Hess[:k + 1, :k], y_k)) < pow(10, -3):\n",
    "            return(u_0 + np.dot(np.transpose(Q[:k]), y_k))\n",
    "        \n",
    "        \n",
    "        \n",
    "    return(u_0 + np.dot(np.transpose(Q), y_k))\n",
    "    \n",
    "#     u_approx = np.zeros(len(f))\n",
    "#     residual = f - np.dot(A, u_approx)\n",
    "    \n",
    "#     r_0 = np.linalg.norm(residual)\n",
    "    \n",
    "#     Q = [residual/r_0]\n",
    "#     Hess = np.zeros((len(f) + 1, len(f)))\n",
    "    \n",
    "    \n",
    "#     for k in range(1, len(f) + 1):\n",
    "#         v = np.dot(A, Q[k - 1])\n",
    "#         for i in range(k):\n",
    "#             Hess[i, k - 1] = np.dot(Q[i], v)\n",
    "#             v = v - Hess[i, k - 1]*Q[i]\n",
    "#         Hess[k, k - 1] = np.linalg.norm(v)\n",
    "#         if k != len(f):\n",
    "#             Q.append(v/Hess[k, k - 1])\n",
    "        \n",
    "        \n",
    "# #     print(Q, Hess)\n",
    "        \n",
    "#         eta = np.zeros(k + 1)\n",
    "#         eta[0] = r_0\n",
    "                \n",
    "#         # Least square problem(Will write a program later)\n",
    "#         y_k = np.linalg.lstsq(Hess[0:k + 1, 0:k], eta)[0]\n",
    "        \n",
    "#         print(Q, y_k)\n",
    "        \n",
    "#         if np.linalg.norm(eta - np.dot(Hess[0:k + 1, 0:k], y_k)) < pow(10, -3):\n",
    "#             return(u_approx + np.dot(Q[:][:-1], y_k))\n",
    "        \n",
    "#     return(u_approx + np.dot(Q, y_k))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "34f303d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q0/zx7hjt_j7bz80q29jndhn7b80000gn/T/ipykernel_21352/2053711827.py:22: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  y_k = np.linalg.lstsq(Hess[:k + 1, :k], eta)[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.5,  2. ,  1. ])"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmres(np.array([[2, 1, 0], [0, 1, 0], [0, 0, 1]]), [1, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "b0fe7ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def multi_grid(A, f, Coeff_matrix_gen):\n",
    "#     if len(f) >= 3:\n",
    "#         nu = random.randint(1, 10)\n",
    "#         u_approx = Jacobi(A, f, nu)\n",
    "#         residual = f - np.dot(A, u_approx)\n",
    "#         course_residual = []\n",
    "#         for i in range(math.floor((m - 1)/2)):\n",
    "#             course_residual.append(u_approx[2*i])\n",
    "\n",
    "#         course_A = Coeff_matrix_gen(math.floor((m - 1)/2))\n",
    "        \n",
    "    \n",
    "#     elif len(f) == 2:\n",
    "#         return(1/(A[0, 0]*A[1, 1] - A[0, 1]*A[1, 0])*np.dot([[A[1, 1], A[0, 0]], [-A[0, 1], -A[1, 0]]], f))\n",
    "    \n",
    "#     else:\n",
    "#         return(1/A[0, 0]*f[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
